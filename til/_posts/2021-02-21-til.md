---
layout: post
title: "2021-02-21 TIL"
tags:
  - [머신러닝]
  - [딥러닝]
  - [기계 학습]
  - [NLP]
---

## 단어 임베딩

---

- Word2vec
  - 주어진 단어에 인접한 단어를 예측 확률
- skip-gram
  - 주변 단어를 예측할 확률을 최대화하는 것이 목표
  - 파라미터 : W(목표/입력 임베딩 행렬), C(상황/출력 임베딩 행렬)
  - Noise-Constrastive Estimation
- Word2vec 학습과정
  1. V개의 d차원 임베딩을 랜덤하게 초기화
  1. 주변 단어들의 쌍을 positive example로 생성
  1. 빈도수에 의해 추출된 단어들의 쌍을 negative example로 생성
  1. 위 데이터를 사용해 분류기 학습
  1. 학습된 임베딩 w가 최종 결과물

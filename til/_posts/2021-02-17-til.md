---
layout: post
title: "2021-02-17 TIL"
tags:
  - [머신러닝]
  - [딥러닝]
  - [기계 학습]
  - [NLP]
---

## 언어모델

---

- 연속적인 단어들에 확률을 부여하는 모델
- 기계 번역, 맞춤법 검사, 음성인식에 필요
- 단어에 대해서 조건부 확률, chain rule 사용
- 조건부 확률을 계산할 충분한 양의 데이터가 없다는 문제점이 있다
  - "한 단어의 확률은 그 단어 앞에 나타나는 몇 개의 단어들에만 의존한다"라는 가정(Markov assumption) 활용
- Unigram 모델 : Markov assumption을 극단적으로 사용한 모델
  - 자주 사용하는 단어들이 생성된다.
- Bigram 모델 : 직전의 단어에만 의존하는 모델
- N-gram 모델으로 확장
- 모델 평가
  - 외재적 평가 : 특정 과제를 위한 부분으로 쓰이기 때문에 과제의 평가지표를 사용
  - 내재적 평가 : 학습률 자체를 평가. 버그가 있는지 확인하는 용도

## 문서 분류

---

- 텍스트가 어떤 범주에 속하는지 구분
- 주제 분류, 스팸 분류, 감성 분류, 언어 분류
- 규칙 기반 모델
  - 규칙 사용
  - Snorkel
- Naive Bayes 분류기
  - Naive Bayes 가정
  - Bag of Words 표현(위치는 확률에 영향을 주지 않는다.)

## 알고리즘

---

- [백준 - 14226 : 이모티콘](https://www.acmicpc.net/problem/14226)
- 이모티콘과 유사한 문제
  - [백준 - 1697 : 숨바꼭질](https://www.acmicpc.net/problem/1697) 풀어보기

---
layout: post
title: "2021-02-20 TIL"
tags:
  - [머신러닝]
  - [딥러닝]
  - [기계 학습]
  - [NLP]
  - [크롤러]
---

## 알고리즘

---

- [백준 - 2343 : 기타레슨](https://www.acmicpc.net/problem/2343)
  - 녹화 길이와 블루레이 크기, 개수 3가지 정보를 가지고 어떻게 left, right(이진 탐색)을 설정할 지 어려웠다.
  - [백준 - 2110 : 공유기](https://www.acmicpc.net/problem/2110) 비슷한 유형의 문제. 나중에 풀기

## 단어 임베딩

---

- 단어간의 관계
  - 어근, 의미
  - 동의어
  - 유사성
  - 연관성(Semantic Field) : 주제, 영역 공유
  - 벡터로 표현 : 주변의 단어들의 분포 표현 -> 임베딩
  - 벡터 공간 내에서 비슷한 단어들은 가까이 분포
- 임베딩의 종류
  - sparse vector(대부분의 원소 값이 0인 경우)
    - tf-idf
    - vector propagation
  - dense vector(대부분의 원소 값이 0인 아닌 경우)
    - word2vec
    - glove
- Term-document 행렬
  - 문서를 기준으로 문서에 나타난 단어들의 빈도를 가지고 벡터로 표현
- 단어 벡터
  - 단어를 기준으로 문서에서의 기준 단어 빈도를 가지고 벡터로 표현
- word-word 행렬(term-context 행렬)
  - 단어를 기준으로 주변 단어들의 빈도를 벡터로 표현
- TF-IDF : 의미를 구분하기 위해 가중치 값을 부여
  - TF : 문서에 나타나는 단어의 빈도 수
  - DF : 단어 t를 포함하는 문서들의 개수
  - IDF(inverse document frequency) : DF의 역수 \* 전체 문서의 개수
  - log를 활용해서 스무딩
  - 변별력이 없는 단어는 0값에 가까워짐
- Dense vector가 선호되는 이유
  - 적은 개수의 학습파라미터
  - 더 나은 일반화 : 너무 일반화시키면 차이를 무시할 수 있음
  - 동의어, 유사어를 더 잘 표현
